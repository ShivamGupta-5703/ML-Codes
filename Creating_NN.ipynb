{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeO4s30tvyc9lLVST1M5pX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install nnfs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rn8D6qKY5QOf","executionInfo":{"status":"ok","timestamp":1679838732753,"user_tz":-330,"elapsed":9031,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}},"outputId":"6589ce52-d4ee-4e7b-e163-4fe192b2b53e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nnfs\n","  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from nnfs) (1.22.4)\n","Installing collected packages: nnfs\n","Successfully installed nnfs-0.5.1\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import nnfs     \n","from nnfs.datasets import spiral_data\n","from nnfs.datasets import vertical_data\n","import matplotlib.pyplot as plt"],"metadata":{"id":"xGbTSoku0mKp","executionInfo":{"status":"ok","timestamp":1679838737977,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["nnfs.init()   #initialize get random value #geneartes same value every time\n","\n","class Layer_Dense:\n","  def __init__(self, n_input, n_neurons):\n","    self.weights = 0.10 * np.random.rand(n_input, n_neurons)\n","    self.biases = np.zeros((1, n_neurons), dtype=float, order='C')\n","    \n","  def forward(self, inputs):\n","    self.output = np.dot(inputs, self.weights) + self.biases\n"],"metadata":{"id":"YtSr_djg4iHu","executionInfo":{"status":"ok","timestamp":1679838741325,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X, y = vertical_data(samples=100, classes=3)    #X = 2 features , y = 3 labels. "],"metadata":{"id":"3iIq7WNB6BpY","executionInfo":{"status":"ok","timestamp":1679838747070,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dense = Layer_Dense(2, 3) # first dense layer, 2 input"],"metadata":{"id":"1Mr-a3Jm8MSv","executionInfo":{"status":"ok","timestamp":1679839650975,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dense.weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nO9rctrUMtwK","executionInfo":{"status":"ok","timestamp":1679839653169,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}},"outputId":"8661f1fd-2eeb-41d7-e1d2-d2730e6f33f9"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.03917969, 0.02421786, 0.02503982],\n","       [0.04833935, 0.00399928, 0.06397051]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["dense.biases"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odtMEpmTMzJA","executionInfo":{"status":"ok","timestamp":1679839655595,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}},"outputId":"dce2b8b1-fdfc-4953-d374-142d410eac6f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0.]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["dense.forward(X)"],"metadata":{"id":"1xwjxaiV_fcF","executionInfo":{"status":"ok","timestamp":1679839657930,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["dense.output"],"metadata":{"id":"wHvVdV1kA3ai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Activation_ReLU:\n","    def forward(self, inputs):\n","        self.output = np.maximum(0, inputs)"],"metadata":{"id":"xcmfiSvhDINm","executionInfo":{"status":"ok","timestamp":1679839667622,"user_tz":-330,"elapsed":1,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["activation = Activation_ReLU()"],"metadata":{"id":"V3P8S15CDKS9","executionInfo":{"status":"ok","timestamp":1679839668869,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["activation.forward(dense.output)"],"metadata":{"id":"jsnVI9q4DTLy","executionInfo":{"status":"ok","timestamp":1679839669582,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["activation.output"],"metadata":{"id":"k0RYg7iLEDFJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Activation_Softmax:\n","    def forward(self, inputs):\n","        exp_val = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n","        prob = exp_val / np.sum(exp_val, axis=1, keepdims=True)\n","        self.output = prob"],"metadata":{"id":"YJ-wzYb1EVFq","executionInfo":{"status":"ok","timestamp":1679839670883,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["act = Activation_Softmax()\n","act.forward(activation.output)"],"metadata":{"id":"i_JsxknXEWuS","executionInfo":{"status":"ok","timestamp":1679839674439,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["act.output"],"metadata":{"id":"gcT3q4mZEiTz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model\n","dense1 = Layer_Dense(2, 3) # first dense layer, 2 inputs\n","activation1 = Activation_ReLU()\n","\n","dense2 = Layer_Dense(3, 3) # first dense layer, 2 inputs\n","activation2 = Activation_ReLU()\n","\n","dense3 = Layer_Dense(3, 3) # first dense layer, 2 inputs\n","activation3 = Activation_Softmax()\n","\n","dense1.forward(X)\n","activation1.forward(dense1.output)\n","\n","dense2.forward(activation1.output)\n","activation2.forward(dense2.output)\n","\n","dense3.forward(activation2.output)\n","activation3.forward(dense3.output)\n","\n","activation3.output"],"metadata":{"id":"Kzu5rzpnOlXO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(X[:, 0], X[:, 1], c=y, cmap='brg')\n","plt.show()"],"metadata":{"id":"Ubx5dgRuNZn8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Loss:\n","    def calculate(self, output, y):\n","        sample_losses = self.forward(output, y)\n","        data_loss = np.mean(sample_losses)\n","        return data_loss\n","\n","class Loss_CategoricalCrossentropy(Loss):\n","    def forward(self, y_pred, y_true):\n","        samples = len(y_pred)\n","        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n","\n","        if len(y_true.shape) == 1:\n","            correct_conf = y_pred_clipped[range(samples), y_true]\n","        elif len(y_true.shape) == 2:\n","            correct_conf = np.sum(y_pred_clipped * y_true, axis=1)\n","        neg_log_lhd = -np.log(correct_conf)\n","        return neg_log_lhd"],"metadata":{"id":"2K44t9QH_ZvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create model\n","activation1 = Activation_ReLU()\n","dense2 = Layer_Dense(3, 3) # second dense layer, 3 inputs, 3 outputs\n","activation2 = Activation_Softmax()\n","# Create loss function\n","loss_function = Loss_CategoricalCrossentropy()\n","dense1.output()\n","\n","\n","print(dense1.weights)\n","\n","# Helper variables\n","lowest_loss = 9999999 # some initial value\n","best_dense1_weights = dense1.weights.copy()\n","best_dense1_biases = dense1.biases.copy()\n","best_dense2_weights = dense2.weights.copy()\n","best_dense2_biases = dense2.biases.copy()\n","\n","for iteration in range(10000):\n","    # Generate a new set of weights for iteration\n","    dense1.weights += 0.05 * np.random.randn(2, 3)\n","    dense1.biases += 0.05 * np.random.randn(1, 3)\n","    dense2.weights += 0.05 * np.random.randn(3, 3)\n","    dense2.biases += 0.05 * np.random.randn(1, 3)\n","\n","    # Perform a forward pass of the training data through this layer\n","    dense1.forward(X)\n","    activation1.forward(dense1.output)\n","    dense2.forward(activation1.output)\n","    activation2.forward(dense2.output)\n","\n","    # Perform a forward pass through activation function\n","    # it takes the output of second dense layer here and returns loss\n","    loss = loss_function.calculate(activation2.output, y)\n","\n","    # Calculate accuracy from output of activation2 and targets\n","    # calculate values along first axis\n","    predictions = np.argmax(activation2.output, axis=1)\n","    accuracy = np.mean(predictions==y)\n","    # If loss is smaller - print and save weights and biases aside\n","    if loss < lowest_loss:\n","        print('New set of weights found, iteration:', iteration, 'loss:', loss, 'acc:', accuracy)\n","        best_dense1_weights = dense1.weights.copy()\n","        best_dense1_biases = dense1.biases.copy()\n","        best_dense2_weights = dense2.weights.copy()\n","        best_dense2_biases = dense2.biases.copy()\n","        lowest_loss = loss\n","        # Revert weights and biases\n","    else:\n","        dense1.weights = best_dense1_weights.copy()\n","        dense1.biases = best_dense1_biases.copy()\n","        dense2.weights = best_dense2_weights.copy()\n","        dense2.biases = best_dense2_biases.copy()"],"metadata":{"id":"zoEcFe680h8H"},"execution_count":null,"outputs":[]}]}