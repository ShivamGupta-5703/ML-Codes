{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YzishTFk6o8VfRJTbgY57ptqD3UOzcF4","authorship_tag":"ABX9TyNa0B9hEULbDVYLo0JwgZB+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PZjjupbIqiIK","executionInfo":{"status":"ok","timestamp":1679494190281,"user_tz":-330,"elapsed":2517,"user":{"displayName":"Shivam Gupta","userId":"06864576598689351732"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random as rd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.neural_network import MLPRegressor\n","#MLPClassifier for classifier problem\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","source":["data = pd.read_excel(\"/content/ENB2012_data.xlsv\")\n","data - data.sample(frac=1) # shuffling the data(sample) and keep 100% of it(frac).\n","\n","\n","#Original data\n","x_org_data = pd.DataFrame(data, columns=[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\"]) #features\n","y1 = pd.DataFrame(data, columns=[\"Y1\"]).values   #output (target1)\n","y2 = pd.DataFrame(data, columns=[\"Y2\"]).values   #output (target2)\n","\n","x_with_dummies = pd.get_dummies(x_org_data,columns=[\"X6\",\"X8\"])\n","minmax_scaler = preprocessing.MinMaxScaler() \n","X = minmax_scaler.fit_transform(x_with_dummies)\n","\n","Y = y1[:,0]\n","cnt1 = len(x)\n","\n","# 10, 4, 0, 1, 0, 1, 1, 0, 0\n","# 10 - no of neurons in each hidden layer [discrete]\n","# 4 - no of hidden layers [discrete]\n","# 0, 1, 0, 1, 1, 0, 0 - binary chromosome representing learning rate and momentum [continous]\n","\n","# con - continous ( 0, 1, 0, 1, 1, 0, 0)\n","# comb - combinatorial (discrete)(10,4)\n","prob_cross_neuron_hlayers = 0.3 # Probability of crossover in neurons and hidden layer\n","prob_cross_chromosome = 1 # Probability of crossover for chormosome\n","prob_mut_neuron_hlayers = 0.2 # Probability of mutation in neurons and hidden layer\n","prob_mut_chromosome = 0.1 # Probability of mutation for crossover for chormosome\n","prob_mut_solver = 0.3 # Probability of mutation for the solver  # using \"adam\" as solver\n","K = 3 # For Tournament selection .No of parents taken for touranment selection(parent among 3 parents with highest obj_value willl be selected)\n","pop = 50 # Population per generation\n","gen = 30 # Number of generations\n","ii2 = 3 # Number of Kfolds\n","\n","\n","\n","### Combinatorial ###\n","### Neurons and Hidden layers ###\n","UB_neuron = 10      #Upper bound Number of Neurons\n","LB_neuron = 6       #Lower bound Number of Neurons\n","UB_hlayer = 8       #Upper bound Number of Hidden Layers\n","LB_hlayer = 3       #Lower bound Number of Hidden Layers\n","\n","\n","### Continuous ###\n","### Chromosome ###\n","# Where the first 15 represent X and the second 15 represent Y.\n","XY = np.array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n","               0, 1,1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1]) # Initial solution\n","\n","Initial_Sol = XY.copy()     # Creating copy of initial solution \n","\n","n_list = np.empty((0,len(XY)+2))             \n","n_listof_ST = np.empty((0,len(XY)+2))          #appending solver type generated randomly (adam in our case).  #This list will contain data on solver used.Since we have used Adam as an only solver .This list will contain only adam.\n","new_population_generated = np.empty((0,len(XY)+2))           #appending new population here craeted randomly.   #This list will contain new chromosome generated again and again,till list size is equal to population.\n","Sol_Here_ST = np.empty((0,1))                \n","\n","Solver_Type = ['adam']\n","\n","#generating population\n","for i in range(pop): # Shuffles the elements in the vector n times and stores them to generate initial population\n","    ST = rd.choice(Solver_Type)  #always adam because we have initialed Solver_Type will adam only.\n","    X1 = rd.randrange(6,10,2)    #step of 2 , so our neurons would be randomly generated between 6,8 or 10   #UB_neuron = 10,LB_neuron = 6\n","    X2 = rd.randrange(3,8,1)     #step of 1 , so our neurons would be randomly generated between 3,4,5,6,7,8 #UB_hlayer = 8,LB_hlayer = 3\n","    rd.shuffle(XY)\n","    new_population_generated = np.append((X1,X2),XY)       #appending new solution to shuffled XY chromosme in Sol_Here list.\n","    n_listof_ST = np.append(n_listof_ST,ST)    #appending solver(adam)  #list will just contain name adam # beneficial when we use different soslvers\n","    n_list = np.vstack((n_list,new_population_generated))  #appending solution\n","\n","# Calculating fitness value\n","\n","# X = Learning Rate\n","lb_X = 0.01 # Lower bound of X\n","ub_X = 0.3 # Upper bound of X\n","l_X = (len(XY)/2) # Length of Chrom. X\n","\n","# Y = Momentum\n","lb_Y = 0.01 # Lower bound of Y\n","ub_Y = 0.99 # Upper bound of Y\n","l_Y = (len(XY)/2) # Length of Chrom. Y\n","\n","\n","#Decoding values of X and Y.\n","Precision_X = (ub_X - lb_X)/((2**l_X)-1)\n","Precision_Y = (ub_Y - lb_Y)/((2**l_Y)-1)\n","\n","\n","z = 0\n","t = 1\n","X_num_Sum = 0   #sum of bits in X chromosome\n","for i in range(len(XY)//2):\n","    X_num = XY[-t]*(2**z)\n","    X_num_Sum += X_num\n","    t = t+1\n","    z = z+1\n","\n","p = 0\n","u = 1 + (len(XY)//2)\n","Y_num_Sum = 0   #sum of bits in Y chromosome\n","for j in range(len(XY)//2):\n","    Y_num = XY[-u]*(2**p)\n","    Y_num_Sum += Y_num\n","    u = u+1\n","    p = p+1\n","\n","\n","Decoded_X = (X_num_Sum * Precision_X) + lb_X\n","Decoded_Y = (Y_num_Sum * Precision_Y) + lb_Y\n","\n","\n","print()\n","print(\"Decoded_X:\",Decoded_X)\n","print(\"Decoded_Y:\",Decoded_Y)\n","\n","\n","For_Plotting_the_Best = np.empty((0,len(new_population_generated)+1))\n","\n","Very_Final_Solution = np.empty((0,len(new_population_generated)+2))\n","Very_Final_Solution_Final = []\n","\n","Min_for_all_Generations_for_Mut_1 = np.empty((0,len(new_population_generated)+1))\n","Min_for_all_Generations_for_Mut_2 = np.empty((0,len(new_population_generated)+1))\n","\n","Min_for_all_Generations_for_Mut_1_1 = np.empty((0,len(new_population_generated)+2))\n","Min_for_all_Generations_for_Mut_2_2 = np.empty((0,len(new_population_generated)+2))\n","\n","Min_for_all_Generations_for_Mut_1_1_1 = np.empty((0,len(new_population_generated)+2))\n","Min_for_all_Generations_for_Mut_2_2_2 = np.empty((0,len(new_population_generated)+2))\n","\n","\n","\n","Generation = 1 \n","\n","\n","for i in range(gen):\n","    \n","    \n","    New_Population = np.empty((0,len(new_population_generated))) # Saving the new generation\n","    \n","    All_in_Generation_X_1 = np.empty((0,len(new_population_generated)+1))\n","    All_in_Generation_X_2 = np.empty((0,len(new_population_generated)+1))\n","    \n","    Min_in_Generation_X_1 = []\n","    Min_in_Generation_X_2 = []\n","    \n","    \n","    Save_Best_in_Generation_X = np.empty((0,len(new_population_generated)+1))\n","    Final_Best_in_Generation_X = []\n","    Worst_Best_in_Generation_X = []\n","    \n","    \n","    print()\n","    print(\"--> GENERATION: #\",Generation)\n","    \n","    Family = 1\n","\n","    for j in range(int(pop/2)): # range(int(pop/2))\n","            \n","        print()\n","        print(\"--> FAMILY: #\",Family)\n","              \n","            \n","        # Tournament Selection\n","        # Tournament Selection\n","        # Tournament Selection\n","        \n","        Parents = np.empty((0,len(new_population_generated)))\n","        #this list will contain two parents.\n","        #in each iteration we will create three warriors and select warrior with minimum error as our parent \n","        \n","        for i in range(2):\n","            \n","            Battle_Troops = []\n","            \n","            Warrior_1_index = np.random.randint(0,len(n_list)) #3\n","            Warrior_2_index = np.random.randint(0,len(n_list)) #5\n","            Warrior_3_index = np.random.randint(0,len(n_list))\n","            \n","            while Warrior_1_index == Warrior_2_index:\n","                Warrior_1_index = np.random.randint(0,len(n_list))\n","            while Warrior_2_index == Warrior_3_index:\n","                    Warrior_3_index = np.random.randint(0,len(n_list))\n","            while Warrior_1_index == Warrior_3_index:\n","                    Warrior_3_index = np.random.randint(0,len(n_list))\n","            \n","            Warrior_1 = n_list[Warrior_1_index,:]    #selecting row whose index is generated and all column\n","            Warrior_2 = n_list[Warrior_2_index,:]\n","            Warrior_3 = n_list[Warrior_3_index,:]\n","            \n","            \n","            Battle_Troops = [Warrior_1,Warrior_2,Warrior_3]\n","            \n","            \n","            # For Warrior #1\n","            \n","            W1_Comb_1 = Warrior_1[0]            #neurons of warrior 1\n","            W1_Comb_1 = int(W1_Comb_1)\n","            W1_Comb_2 = Warrior_1[1]            #hidden layers of warrior 1\n","            W1_Comb_2 = int(W1_Comb_2)\n","            \n","            W1_Con = Warrior_1[2:]              #chromosome of warrior 1  #index 0 for neuron ,index 1 for hidden layer and onwards is chromosome\n","            \n","            X_num_Sum_W1 = 0     #calculating sum of bits in chromosome X of warrior 1 \n","            Y_num_Sum_W1 = 0     #calculating sum of bits in chromosome Y of warrior 1 \n","            \n","            z = 0\n","            t = 1\n","            OF_So_Far_W1 = 0\n","            \n","            for i in range(len(XY)//2):\n","                X_num_W1 = W1_Con[-t]*(2**z)\n","                X_num_Sum_W1 += X_num_W1\n","                t = t+1\n","                z = z+1\n","                \n","            p = 0\n","            u = 1 + (len(XY)//2)\n","            \n","            for j in range(len(XY)//2):\n","                Y_num_W1 = W1_Con[-u]*(2**p)\n","                Y_num_Sum_W1 += Y_num_W1\n","                u = u+1\n","                p = p+1\n","                \n","\n","            #Decoding values of X and Y chromosome of warrior 1.\n","            Decoded_X_W1 = (X_num_Sum_W1 * Precision_X) + lb_X   #learning rate \n","            Decoded_Y_W1 = (Y_num_Sum_W1 * Precision_Y) + lb_Y   #momentum\n","            '''\n","            print(\"Decoded_X_W1:\", Decoded_X_W1)\n","            print(\"Decoded_Y_W1:\",Decoded_Y_W1)\n","            '''  \n","            \n","            Emp_3 = 0   #initial error\n","\n","            kf = KFold(n_splits=ii2)\n","            \n","            for train_index, test_index in kf.split(X):             #loop iterates 3 times because no of kfolds =3\n","                X_train, X_test = X[train_index], X[test_index]\n","                Y_train, Y_test = Y[train_index], Y[test_index]\n","                \n","                Hid_Lay = ()  \n","    \n","                # Objective Function\n","                \n","                #Since we know we have equal number of neurons in hidden layers\n","                #let no of neurons be 8 in each layer   \n","                for i in range(W1_Comb_2):   #no of hidden layers of warrior 1.\n","                    Hid_Lay = Hid_Lay + (W1_Comb_1,)     #hidden layer + no of neurons  #hidden layer+8\n","                  \n","                model1 = MLPRegressor(activation='relu',hidden_layer_sizes=Hid_Lay,\n","                                       learning_rate_init=Decoded_X_W1,momentum=Decoded_Y_W1)\n","        \n","                model1.fit(X_train, Y_train)   #training model\n","                PL1=model1.predict(X_test)     #testing model\n","                AC1=model1.score(X_test,Y_test)   #accuracy\n","            \n","                error_in_each_iteration = 1-(model1.score(X_test,Y_test))  # 1 - Accuracy\n","                \n","                \n","                Emp_3 += error_in_each_iteration\n","            \n","            error_of_W1 = Emp_3/ii2     #Average of error \n","            \n","            '''\n","            print()\n","            print(\"OF_So_Far_W1:\",(1-OF_So_Far_W1))\n","            '''\n","            Prize_Warrior_1 = error_of_W1\n","            \n","            \n","            # For Warrior #2\n","            \n","            W2_Comb_1 = Warrior_2[0]\n","            W2_Comb_1 = int(W2_Comb_1)\n","            W2_Comb_2 = Warrior_2[1]\n","            W2_Comb_2 = int(W2_Comb_2)\n","            \n","            W2_Con = Warrior_2[2:]\n","            \n","            X0_num_Sum_W2 = 0\n","            Y0_num_Sum_W2 = 0\n","            \n","            z = 0\n","            t = 1\n","            OF_So_Far_W2 = 0\n","        \n","            for i in range(len(XY)//2):\n","                X0_num_W2 = W2_Con[-t]*(2**z)\n","                X0_num_Sum_W2 += X0_num_W2\n","                t = t+1\n","                z = z+1\n","                \n","            p = 0\n","            u = 1 + (len(XY)//2)\n","            \n","            for j in range(len(XY)//2):\n","                Y0_num_W2 = W2_Con[-u]*(2**p)\n","                Y0_num_Sum_W2 += Y0_num_W2\n","                u = u+1\n","                p = p+1\n","                \n","        \n","            Decoded_X3_W2 = (X0_num_Sum_W2 * Precision_X) + lb_X\n","            Decoded_X4_W2 = (Y0_num_Sum_W2 * Precision_Y) + lb_Y\n","            '''\n","            print(\"Decoded_X_W2:\", Decoded_X_W2)\n","            print(\"Decoded_Y_W2:\",Decoded_Y_W2)\n","            '''  \n","            \n","            Emp_4 = 0\n","\n","            kf =KFold(n_splits=ii2)\n","            \n","            for train_index, test_index in kf.split(X):\n","                X_train, X_test = X[train_index], X[test_index]\n","                Y_train, Y_test = Y[train_index], Y[test_index]\n","                \n","                Hid_Lay = ()\n","    \n","                # Objective Function\n","                \n","                for i in range(W2_Comb_2):\n","                    Hid_Lay = Hid_Lay + (W2_Comb_1,)\n","                  \n","                model1 = MLPRegressor(activation='relu',hidden_layer_sizes=Hid_Lay,\n","                                       learning_rate_init=Decoded_X3_W2,momentum=Decoded_X4_W2)\n","        \n","                model1.fit(X_train, Y_train)\n","                PL1=model1.predict(X_test)\n","                AC1=model1.score(X_test,Y_test)\n","            \n","                OF_So_Far_4 = 1-(model1.score(X_test,Y_test))\n","                \n","                \n","                Emp_4 += OF_So_Far_4\n","            \n","            OF_So_Far_W2 = Emp_4/ii2\n","            \n","            '''\n","            print()\n","            print(\"OF_So_Far_W2:\",(1-OF_So_Far_W2))\n","            '''\n","            Prize_Warrior_2 = OF_So_Far_W2\n","            \n","            \n","            # For Warrior #3\n","            \n","            W3_Comb_1 = Warrior_3[0]\n","            W3_Comb_1 = int(W3_Comb_1)\n","            W3_Comb_2 = Warrior_3[1]\n","            W3_Comb_2 = int(W3_Comb_2)\n","            \n","            W3_Con = Warrior_3[2:]\n","            \n","            X0_num_Sum_W3 = 0\n","            Y0_num_Sum_W3 = 0\n","            \n","            z = 0\n","            t = 1\n","            OF_So_Far_W3 = 0\n","        \n","            for i in range(len(XY)//2):\n","                X0_num_W3 = W3_Con[-t]*(2**z)\n","                X0_num_Sum_W3 += X0_num_W3\n","                t = t+1\n","                z = z+1\n","                \n","            p = 0\n","            u = 1 + (len(XY)//2)\n","            \n","            for j in range(len(XY)//2):\n","                Y0_num_W3 = W3_Con[-u]*(2**p)\n","                Y0_num_Sum_W3 += Y0_num_W3\n","                u = u+1\n","                p = p+1\n","                \n","        \n","            Decoded_X3_W3 = (X0_num_Sum_W3 * Precision_X) + lb_X\n","            Decoded_X4_W3 = (Y0_num_Sum_W3 * Precision_Y) + lb_Y\n","            '''\n","            print(\"Decoded_X_W3:\", Decoded_X_W3)\n","            print(\"Decoded_Y_W3:\",Decoded_Y_W3)\n","            '''  \n","            \n","            Emp_5 = 0\n","\n","            kf = KFold(n_splits=ii2)\n","            \n","            for train_index, test_index in kf.split(X):\n","                X_train, X_test = X[train_index], X[test_index]\n","                Y_train, Y_test = Y[train_index], Y[test_index]\n","                \n","                Hid_Lay = ()\n","    \n","                # Objective Function\n","                \n","                for i in range(W3_Comb_2):\n","                    Hid_Lay = Hid_Lay + (W3_Comb_1,)\n","                  \n","                model1 = MLPRegressor(activation='relu',hidden_layer_sizes=Hid_Lay,\n","                                       learning_rate_init=Decoded_X3_W3,momentum=Decoded_X4_W3)\n","        \n","                model1.fit(X_train, Y_train)\n","                PL1=model1.predict(X_test)\n","                AC1=model1.score(X_test,Y_test)\n","            \n","                OF_So_Far_5 = 1-(model1.score(X_test,Y_test))\n","                \n","                \n","                Emp_5 += OF_So_Far_5\n","            \n","            OF_So_Far_W3 = Emp_5/ii2\n","            \n","            '''\n","            print()\n","            print(\"OF_So_Far_W3:\",(1-OF_So_Far_W3))\n","            '''\n","            Prize_Warrior_3 = OF_So_Far_W3 \n","\n","            \n","            #warrior with minimum error is selected as parents\n","            if Prize_Warrior_1 == min(Prize_Warrior_1,Prize_Warrior_2,Prize_Warrior_3):\n","                Winner = Warrior_1\n","                Winner_str = \"Warrior_1\"\n","                Prize = Prize_Warrior_1\n","            elif Prize_Warrior_2 == min(Prize_Warrior_1,Prize_Warrior_2,Prize_Warrior_3):\n","                Winner = Warrior_2\n","                Winner_str = \"Warrior_2\"\n","                Prize = Prize_Warrior_2\n","            else:\n","                Winner = Warrior_3\n","                Winner_str = \"Warrior_3\"\n","                Prize = Prize_Warrior_3\n","            '''\n","            print()\n","            print(\"Prize_Warrior_1:\",Prize_Warrior_1)\n","            print(\"Prize_Warrior_2:\",Prize_Warrior_2)\n","            print(\"Prize_Warrior_3:\",Prize_Warrior_3)\n","            print(\"Winner is:\",Winner_str,\"at:\",Prize)\n","            '''\n","            Parents = np.vstack((Parents,Winner))  #selected warrior is added in parents list as a parent\n","        '''\n","        print()\n","        print(\"Parents:\",Parents)\n","        '''\n","        \n","        Parent_1 = Parents[0]\n","        Parent_2 = Parents[1]\n","        \n","        \n","        # Crossover\n","        # Crossover\n","        # Crossover\n","        \n","        #two empty arrays for 2 children\n","        Child_1 = np.empty((0,len(new_population_generated)))\n","        Child_2 = np.empty((0,len(new_population_generated)))\n","        \n","        \n","        # Crossover the Integers\n","        # Combinatorial  \n","        #Neurons\n","        \n","        #if probaility high then exchange number of neurons of parent 1 and parent 2.\n","        # For X1\n","        Ran_CO_1 = np.random.rand()\n","        if Ran_CO_1 < prob_cross_neuron_hlayers:\n","            # For X1\n","            Int_X1_1 = Parent_2[0]\n","            Int_X1_2 = Parent_1[0]\n","        else:\n","            # For X1\n","            Int_X1_1 = Parent_1[0]\n","            Int_X1_2 = Parent_2[0]\n","        \n","        # For X2\n","        # For X2\n","        Ran_CO_1 = np.random.rand()\n","        if Ran_CO_1 < prob_cross_neuron_hlayers:\n","            # For X2\n","            Int_X2_1 = Parent_2[1]\n","            Int_X2_2 = Parent_1[1]\n","        else:\n","            # For X2\n","            Int_X2_1 = Parent_1[1]\n","            Int_X2_2 = Parent_2[1]\n","        \n","        \n","        # Continuous\n","        # Where to crossover\n","        # Two-point crossover\n","        \n","        Ran_CO_1 = np.random.rand()\n","        \n","        if Ran_CO_1 < prob_cross_chromosome:\n","          \n","          #starting from index 2 because index 0 is for neurons and index 1 for hidden layers\n","            Cr_1 = np.random.randint(2,len(new_population_generated))\n","            Cr_2 = np.random.randint(2,len(new_population_generated))\n","                \n","            while Cr_1 == Cr_2:\n","                Cr_2 = np.random.randint(2,len(new_population_generated))\n","            \n","            if Cr_1 < Cr_2:\n","                \n","                Cr_2 = Cr_2 + 1\n","                \n","                Copy_1 = Parent_1[2:]\n","                Mid_Seg_1 = Parent_1[Cr_1:Cr_2]\n","                \n","                Copy_2 = Parent_2[2:]\n","                Mid_Seg_2 = Parent_2[Cr_1:Cr_2]\n","                \n","                First_Seg_1 = Parent_1[2:Cr_1]\n","                Second_Seg_1 = Parent_1[Cr_2:]\n","                \n","                First_Seg_2 = Parent_2[2:Cr_1]\n","                Second_Seg_2 = Parent_2[Cr_2:]\n","                \n","                Child_1 = np.concatenate((First_Seg_1,Mid_Seg_2,Second_Seg_1))\n","                Child_2 = np.concatenate((First_Seg_2,Mid_Seg_1,Second_Seg_2))\n","                \n","                Child_1 = np.insert(Child_1,0,(Int_X1_1,Int_X2_1))###\n","                Child_2 = np.insert(Child_2,0,(Int_X1_2,Int_X2_2))\n","            else:\n","                \n","                Cr_1 = Cr_1 + 1\n","                \n","                Copy_1 = Parent_1[2:]\n","                Mid_Seg_1 = Parent_1[Cr_2:Cr_1]\n","                \n","                Copy_2 = Parent_2[2:]\n","                Mid_Seg_2 = Parent_2[Cr_2:Cr_1]\n","                \n","                First_Seg_1 = Parent_1[2:Cr_2]\n","                Second_Seg_1 = Parent_1[Cr_1:]\n","                \n","                First_Seg_2 = Parent_2[2:Cr_2]\n","                Second_Seg_2 = Parent_2[Cr_1:]\n","                \n","                Child_1 = np.concatenate((First_Seg_1,Mid_Seg_2,Second_Seg_1))\n","                Child_2 = np.concatenate((First_Seg_2,Mid_Seg_1,Second_Seg_2))\n","                Child_1 = np.insert(Child_1,0,(Int_X1_1,Int_X2_1))###\n","                Child_2 = np.insert(Child_2,0,(Int_X1_2,Int_X2_2))\n","        else:\n","            \n","            Child_1 = Parent_1[2:]\n","            Child_2 = Parent_2[2:]\n","            '''\n","            print()\n","            print(\"Child #1 here2:\",Child_1)\n","            print(\"Child #2 here2:\",Child_2)\n","            '''\n","            Child_1 = np.insert(Child_1,0,(Int_X1_1,Int_X2_1))###\n","            Child_2 = np.insert(Child_2,0,(Int_X1_2,Int_X2_2))\n","            \n","            \n","        '''    \n","        print()\n","        print(\"Child #1:\",Child_1)\n","        print(\"Child #2:\",Child_2)\n","        '''\n","        '''\n","        print(\"Cr_1:\",Cr_1)\n","        print(\"Cr_2:\",Cr_2)\n","        print(\"Parent #1:\",Parent_1)\n","        print(\"Parent #2:\",Parent_2)\n","        print(\"Child #1:\",Child_1)\n","        print(\"Child #2:\",Child_2)\n","        '''\n","        \n","        \n","        # Mutation Child #1\n","        # Mutation Child #1\n","        # Mutation Child #1\n","        \n","        Mutated_Child_1 = []\n","        \n","        \n","        # Combinatorial\n","        \n","        #for neurons\n","        # For X1\n","        # For X1\n","        Ran_M1_1 = np.random.rand()\n","        if Ran_M1_1 < prob_mut_neuron_hlayers:\n","            Ran_M1_2 = np.random.rand()\n","            if Ran_M1_2 >= 0.5:\n","                if Child_1[0] == ub_X:\n","                    C_X1_M1 = Child_1[0]\n","                elif Child_1[0] == lb_X:\n","                    C_X1_M1 = Child_1[0]\n","                else:\n","                    C_X1_M1 = Child_1[0] + 2\n","            else:\n","                if Child_1[0] == ub_X:\n","                    C_X1_M1 = Child_1[0]\n","                elif Child_1[0] == lb_X:\n","                    C_X1_M1 = Child_1[0]\n","                else:\n","                    C_X1_M1 = Child_1[0] - 2\n","        else:\n","            C_X1_M1 = Child_1[0]\n","        \n","        #for hidden layers\n","        # For X2\n","        # For X2\n","        Ran_M1_3 = np.random.rand()\n","        if Ran_M1_3 < prob_mut_neuron_hlayers:\n","            Ran_M1_4 = np.random.rand()\n","            if Ran_M1_4 >= 0.5:\n","                if Child_1[1] == ub_X:\n","                    C_X2_M1 = Child_1[1]\n","                elif Child_1[1] == lb_X:\n","                    C_X2_M1 = Child_1[1]\n","                else:\n","                    C_X2_M1 = Child_1[1] + 1\n","            else:\n","                if Child_1[1] == ub_X:\n","                    C_X2_M1 = Child_1[1]\n","                elif Child_1[1] == lb_X:\n","                    C_X2_M1 = Child_1[1]\n","                else:\n","                    C_X2_M1 = Child_1[1] - 1\n","        else:\n","            C_X2_M1 = Child_1[1]\n","           \n","        \n","        # Continuous\n","        \n","        t = 0\n","        \n","        Child_1n = Child_1[2:]\n","        \n","        for i in Child_1n:\n","        \n","            Ran_Mut_1 = np.random.rand() # Probablity to Mutate\n","            \n","            if Ran_Mut_1 < prob_mut_chromosome: # If probablity to mutate is less than p_m, then mutate\n","                \n","                if Child_1n[t] == 0:\n","                    Child_1n[t] = 1\n","                else:\n","                    Child_1n[t] = 0\n","                t = t+1\n","            \n","                Mutated_Child_1n = Child_1n\n","                \n","            else:\n","                Mutated_Child_1n = Child_1n\n","        \n","        Mutated_Child_1 = np.insert(Mutated_Child_1n,0,(C_X1_M1,C_X2_M1))\n","        \n","        '''\n","        print()\n","        print(\"Mutated_Child #1:\",Mutated_Child_1)\n","        '''\n","        \n","        # Mutation Child #2\n","        # Mutation Child #2\n","        # Mutation Child #2\n","        \n","        Mutated_Child_2 = []\n","        \n","        \n","        # Combinatorial\n","        \n","        # For X1\n","        # For X1\n","        Ran_M2_1 = np.random.rand()\n","        if Ran_M2_1 < prob_mut_neuron_hlayers:\n","            Ran_M2_2 = np.random.rand()\n","            if Ran_M2_2 >= 0.5:\n","                if Child_2[0] == ub_X:\n","                    C_X1_M2 = Child_1[0]\n","                elif Child_2[0] == lb_X:\n","                    C_X1_M2 = Child_2[0]\n","                else:\n","                    C_X1_M2 = Child_2[0] + 2\n","            else:\n","                if Child_2[0] == ub_X:\n","                    C_X1_M2 = Child_2[0]\n","                elif Child_1[0] == lb_X:\n","                    C_X1_M2 = Child_2[0]\n","                else:\n","                    C_X1_M2 = Child_1[0] - 2\n","        else:\n","            C_X1_M2 = Child_2[0]\n","        \n","        # For X2\n","        # For X2\n","        Ran_M2_3 = np.random.rand()\n","        if Ran_M2_3 < prob_mut_neuron_hlayers:\n","            Ran_M2_4 = np.random.rand()\n","            if Ran_M2_4 >= 0.5:\n","                if Child_2[1] == ub_Y:\n","                    C_X2_M2 = Child_2[1]\n","                elif Child_2[1] == lb_Y:\n","                    C_X2_M2 = Child_2[1]\n","                else:\n","                    C_X2_M2 = Child_2[1] + 1\n","            else:\n","                if Child_2[1] == ub_Y:\n","                    C_X2_M2 = Child_2[1]\n","                elif Child_2[1] == lb_Y:\n","                    C_X2_M2 = Child_2[1]\n","                else:\n","                    C_X2_M2 = Child_2[1] - 1\n","        else:\n","            C_X2_M2 = Child_2[1]\n","           \n","        \n","        # Continuous\n","        \n","        t = 0\n","        \n","        Child_2n = Child_2[2:]\n","        \n","        for i in Child_2n:\n","        \n","            Ran_Mut_2 = np.random.rand() # Probablity to Mutate\n","            \n","            if Ran_Mut_2 < prob_mut_chromosome: # If probablity to mutate is less than p_m, then mutate\n","                \n","                if Child_2n[t] == 0:\n","                    Child_2n[t] = 1\n","                else:\n","                    Child_2n[t] = 0\n","                t = t+1\n","            \n","                Mutated_Child_2n = Child_2n\n","                \n","            else:\n","                Mutated_Child_2n = Child_2n\n","        \n","        Mutated_Child_2 = np.insert(Mutated_Child_2n,0,(C_X1_M2,C_X2_M2))\n","        \n","        '''\n","        print()\n","        print(\"Mutated_Child #2:\",Mutated_Child_2)\n","        '''\n","        \n","        # Calculate fitness values of mutated children\n","        \n","        fit_val_muted_children = np.empty((0,2))\n","        \n","        \n","        # For mutated child #1\n","        \n","        MC_1_Comb_1 = Mutated_Child_1[0]\n","        MC_1_Comb_1 = int(MC_1_Comb_1)\n","        MC_1_Comb_2 = Mutated_Child_1[1]\n","        MC_1_Comb_2 = int(MC_1_Comb_2)\n","        \n","        MC_1_Con = Mutated_Child_1[2:]\n","        \n","        X0_num_Sum_MC_1 = 0\n","        Y0_num_Sum_MC_1 = 0\n","        \n","        z = 0\n","        t = 1\n","        OF_So_Far_MC_1 = 0\n","    \n","        for i in range(len(XY)//2):\n","            X0_num_MC_1 = MC_1_Con[-t]*(2**z)\n","            X0_num_Sum_MC_1 += X0_num_MC_1\n","            t = t+1\n","            z = z+1\n","            \n","        p = 0\n","        u = 1 + (len(XY)//2)\n","        \n","        for j in range(len(XY)//2):\n","            Y0_num_MC_1 = MC_1_Con[-u]*(2**p)\n","            Y0_num_Sum_MC_1 += Y0_num_MC_1\n","            u = u+1\n","            p = p+1\n","            \n","        Decoded_X3_MC_1 = (X0_num_Sum_MC_1 * Precision_X) + lb_X\n","        Decoded_X4_MC_1 = (Y0_num_Sum_MC_1 * Precision_Y) + lb_Y\n","        \n","        \n","        Emp_6 = 0\n","\n","        kf = KFold(n_splits=ii2)\n","        \n","        for train_index, test_index in kf.split(X):\n","            X_train, X_test = X[train_index], X[test_index]\n","            Y_train, Y_test = Y[train_index], Y[test_index]\n","            \n","            Hid_Lay = ()\n","\n","            # Objective Function\n","            \n","            for i in range(MC_1_Comb_2):\n","                Hid_Lay = Hid_Lay + (MC_1_Comb_1,)\n","              \n","            model1 = MLPRegressor(activation='relu',hidden_layer_sizes=Hid_Lay,\n","                                   learning_rate_init=Decoded_X3_MC_1,momentum=Decoded_X4_MC_1)\n","            model1.fit(X_train, Y_train)\n","            PL1=model1.predict(X_test)\n","            AC1=model1.score(X_test,Y_test)\n","        \n","            OF_So_Far_6 = 1-(model1.score(X_test,Y_test))\n","            \n","            Emp_6 += OF_So_Far_6\n","        \n","        OF_So_Far_MC_1 = Emp_6/ii2\n","        \n","        \n","        # For mutated child #2\n","        \n","        MC_2_Comb_1 = Mutated_Child_2[0]\n","        MC_2_Comb_1 = int(MC_2_Comb_1)\n","        MC_2_Comb_2 = Mutated_Child_2[1]\n","        MC_2_Comb_2 = int(MC_2_Comb_2)\n","        \n","        MC_2_Con = Mutated_Child_2[2:]\n","        \n","        X0_num_Sum_MC_2 = 0\n","        Y0_num_Sum_MC_2 = 0\n","        \n","        z = 0\n","        t = 1\n","        OF_So_Far_MC_2 = 0\n","    \n","        for i in range(len(XY)//2):\n","            X0_num_MC_2 = MC_2_Con[-t]*(2**z)\n","            X0_num_Sum_MC_2 += X0_num_MC_2\n","            t = t+1\n","            z = z+1\n","            \n","        p = 0\n","        u = 1 + (len(XY)//2)\n","        \n","        for j in range(len(XY)//2):\n","            Y0_num_MC_2 = MC_2_Con[-u]*(2**p)\n","            Y0_num_Sum_MC_2 += Y0_num_MC_2\n","            u = u+1\n","            p = p+1\n","            \n","        Decoded_X3_MC_2 = (X0_num_Sum_MC_2 * Precision_X) + lb_X\n","        Decoded_X4_MC_2 = (Y0_num_Sum_MC_2 * Precision_Y) + lb_Y\n","        \n","        \n","        Emp_7 = 0\n","\n","        kf = KFold(n_splits=ii2)\n","        \n","        for train_index, test_index in kf.split(X):\n","            X_train, X_test = X[train_index], X[test_index]\n","            Y_train, Y_test = Y[train_index], Y[test_index]\n","            \n","            Hid_Lay = ()\n","\n","            # Objective Function\n","            \n","            for i in range(MC_2_Comb_2):\n","                Hid_Lay = Hid_Lay + (MC_2_Comb_1,)\n","              \n","            model1 = MLPRegressor(activation='relu',hidden_layer_sizes=Hid_Lay,\n","                                   learning_rate_init=Decoded_X3_MC_2,momentum=Decoded_X4_MC_2)\n","            model1.fit(X_train, Y_train)\n","            PL1=model1.predict(X_test)\n","            AC1=model1.score(X_test,Y_test)\n","        \n","            OF_So_Far_7 = 1-(model1.score(X_test,Y_test))\n","            \n","            Emp_7 += OF_So_Far_7\n","        \n","        OF_So_Far_MC_2 = Emp_7/ii2\n","        \n","        '''\n","        print()\n","        print(\"FV at Mutated Child #1 at Gen #\",Generation,\":\", OF_So_Far_MC_1)\n","        print(\"FV at Mutated Child #2 at Gen #\",Generation,\":\", OF_So_Far_MC_2)\n","        '''   \n","              \n","        All_in_Generation_X_1_1_temp = Mutated_Child_1[np.newaxis]\n","        All_in_Generation_X_1_1 = np.column_stack((OF_So_Far_MC_1, All_in_Generation_X_1_1_temp))\n","        \n","        \n","        All_in_Generation_X_2_1_temp = Mutated_Child_2[np.newaxis]\n","        All_in_Generation_X_2_1 = np.column_stack((OF_So_Far_MC_2, All_in_Generation_X_2_1_temp))\n","        \n","        \n","        All_in_Generation_X_1 = np.vstack((All_in_Generation_X_1,All_in_Generation_X_1_1))\n","        All_in_Generation_X_2 = np.vstack((All_in_Generation_X_2,All_in_Generation_X_2_1))\n","        \n","        \n","        Save_Best_in_Generation_X = np.vstack((All_in_Generation_X_1,All_in_Generation_X_2))\n","        \n","        \n","        New_Population = np.vstack((New_Population,Mutated_Child_1,Mutated_Child_2))\n","        \n","        t = 0\n","        R_1 = []\n","        for i in All_in_Generation_X_1:\n","            \n","            if (All_in_Generation_X_1[t,:1]) <= min(All_in_Generation_X_1[:,:1]):\n","                R_1 = All_in_Generation_X_1[t,:]\n","            t = t+1\n","            \n","        \n","        Min_in_Generation_X_1 = R_1[np.newaxis]\n","        '''\n","        print()\n","        print(\"Min_in_Generation_X_1:\",Min_in_Generation_X_1)\n","        '''\n","        t = 0\n","        R_2 = []\n","        for i in All_in_Generation_X_2:\n","            \n","            if (All_in_Generation_X_2[t,:1]) <= min(All_in_Generation_X_2[:,:1]):\n","                R_2 = All_in_Generation_X_2[t,:]\n","            t = t+1\n","                \n","        \n","        Min_in_Generation_X_2 = R_2[np.newaxis]\n","        '''\n","        print()\n","        print(\"Min_in_Generation_X_2:\",Min_in_Generation_X_2)\n","        '''\n","        \n","        Family = Family+1\n","    \n","    '''\n","    print()\n","    print(\"New_Population Before:\",New_Population)\n","    '''\n","    t = 0\n","    R_Final = []\n","    for i in Save_Best_in_Generation_X:\n","        \n","        if (Save_Best_in_Generation_X[t,:1]) <= min(Save_Best_in_Generation_X[:,:1]):\n","            R_Final = Save_Best_in_Generation_X[t,:]\n","        t = t+1\n","            \n","    \n","    Final_Best_in_Generation_X = R_Final[np.newaxis]\n","    '''\n","    print()\n","    print(\"Final_Best_in_Generation_X:\",Final_Best_in_Generation_X)\n","    '''\n","    t = 0\n","    R_22_Final = []\n","    for i in Save_Best_in_Generation_X:\n","        \n","        if (Save_Best_in_Generation_X[t,:1]) >= max(Save_Best_in_Generation_X[:,:1]):\n","            R_22_Final = Save_Best_in_Generation_X[t,:]\n","        t = t+1\n","            \n","    \n","    Worst_Best_in_Generation_X = R_22_Final[np.newaxis]\n","    '''\n","    print()\n","    print(\"Worst_Best_in_Generation_X:\",Worst_Best_in_Generation_X)\n","    '''\n","    \n","    # Elitism, the best in the generation lives\n","    # Elitism, the best in the generation lives\n","    # Elitism, the best in the generation lives\n","    \n","    Darwin_Guy = Final_Best_in_Generation_X[:]\n","    Not_So_Darwin_Guy = Worst_Best_in_Generation_X[:]\n","    \n","    \n","    Darwin_Guy = Darwin_Guy[0:,1:].tolist()\n","    Not_So_Darwin_Guy = Not_So_Darwin_Guy[0:,1:].tolist()\n","    \n","    '''\n","    print()\n","    print(\"Darwin_Guy:\",Darwin_Guy)\n","    print(\"Not_So_Darwin_Guy:\",Not_So_Darwin_Guy)\n","    \n","    print()\n","    print(\"Before:\",New_Population)\n","    print()\n","    '''\n","    Best_1 = np.where((New_Population == Darwin_Guy).all(axis=1))\n","    Worst_1 = np.where((New_Population == Not_So_Darwin_Guy).all(axis=1))\n","    '''\n","    print()\n","    print(\"Best_1:\",Best_1)\n","    print(\"Worst_1:\",Worst_1)\n","    '''\n","    New_Population[Worst_1] = Darwin_Guy\n","    '''\n","    print(\"New_Population After:\",New_Population)\n","    \n","    print()\n","    print(\"After:\",New_Population)\n","    '''\n","    n_list = New_Population\n","    \n","    '''\n","    print()\n","    print(\"The New Population Are:\\n\",New_Population)\n","    '''\n","    \n","    Min_for_all_Generations_for_Mut_1 = np.vstack((Min_for_all_Generations_for_Mut_1,Min_in_Generation_X_1))\n","    Min_for_all_Generations_for_Mut_2 = np.vstack((Min_for_all_Generations_for_Mut_2,Min_in_Generation_X_2))\n","    \n","    \n","    Min_for_all_Generations_for_Mut_1_1 = np.insert(Min_in_Generation_X_1, 0, Generation)\n","    Min_for_all_Generations_for_Mut_2_2 = np.insert(Min_in_Generation_X_2, 0, Generation)\n","    '''\n","    Min_for_all_Generations_for_Mut_1_1_ST = np.insert(Min_in_Generation_X_1_ST, 0, Generation)\n","    Min_for_all_Generations_for_Mut_2_2_ST = np.insert(Min_in_Generation_X_2_ST, 0, Generation)\n","    '''\n","    Min_for_all_Generations_for_Mut_1_1_1 = np.vstack((Min_for_all_Generations_for_Mut_1_1_1,Min_for_all_Generations_for_Mut_1_1))\n","    Min_for_all_Generations_for_Mut_2_2_2 = np.vstack((Min_for_all_Generations_for_Mut_2_2_2,Min_for_all_Generations_for_Mut_2_2))\n","    \n","    \n","    Generation = Generation+1\n","    \n","    \n","\n","\n","\n","One_Final_Guy = np.vstack((Min_for_all_Generations_for_Mut_1_1_1,Min_for_all_Generations_for_Mut_2_2_2))\n","\n","\n","t = 0\n","Final_Here = []\n","for i in One_Final_Guy:\n","    \n","    if (One_Final_Guy[t,1]) <= min(One_Final_Guy[:,1]):\n","        Final_Here = One_Final_Guy[t,:]\n","    t = t+1\n","        \n","\n","One_Final_Guy_Final = Final_Here[np.newaxis]\n","\n","\n","XY0_Encoded_After = Final_Here[4:]\n","\n","# DECODING\n","# DECODING\n","# DECODING\n","\n","z = 0\n","t = 1\n","X0_num_Sum_Encoded_After = 0\n","\n","for i in range(len(XY)//2):\n","    X0_num_Encoded_After = XY0_Encoded_After[-t]*(2**z)\n","    X0_num_Sum_Encoded_After += X0_num_Encoded_After\n","    t = t+1\n","    z = z+1\n","\n","\n","p = 0\n","u = 1 + (len(XY)//2)\n","Y0_num_Sum_Encoded_After = 0\n","\n","for j in range(len(XY)//2):\n","    Y0_num_Encoded_After = XY0_Encoded_After[-u]*(2**p)\n","    Y0_num_Sum_Encoded_After += Y0_num_Encoded_After\n","    u = u+1\n","    p = p+1\n","\n","\n","Decoded_X_After = (X0_num_Sum_Encoded_After * Precision_X) + lb_X\n","Decoded_Y_After = (Y0_num_Sum_Encoded_After * Precision_Y) + lb_Y\n","\n","print()\n","print()\n","print(\"The High Accuracy is:\",(1-One_Final_Guy_Final[:,1]))\n","print(\"Number of Neurons:\",Final_Here[2])\n","print(\"Number of Hidden Layers:\",Final_Here[3])\n","print(\"Learning Rate:\",Decoded_X_After)\n","print(\"Momentum:\",Decoded_Y_After)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkzLzIqvZd15","outputId":"111be130-51cc-4eb7-d155-3ebe76254b35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> FAMILY: # 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> FAMILY: # 3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> FAMILY: # 4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n","  warnings.warn(\"Training interrupted by user.\")\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> FAMILY: # 5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"V5yqp-MtkXRs"},"execution_count":null,"outputs":[]}]}